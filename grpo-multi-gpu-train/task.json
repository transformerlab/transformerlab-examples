{
  "title": "GRPO Multi-GPU Training Task",
  "name": "grpo-multi-gpu-train-task",
  "command": "cd ~/grpo-multi-gpu-train && python train.py",
  "accelerators": "A100-80GB:1",
  "setup": "uv pip install trl bitsandbytes accelerate transformerlab datasets jinja2 wandb",
  "env_vars": {
    "WANDB_PROJECT": "grpo-multi-gpu-training",
    "WANDB_API_KEY": "ENTER YOUR WANDB_API_KEY HERE",
    "PYTHONUNBUFFERED": "1",
    "HF_TOKEN": "ENTER YOUR HF_TOKEN HERE"
  },
  "description": "A GRPO trainer using multi-GPU setup trained with TRL and Accelerate for distributed training across multiple GPUs."
}
