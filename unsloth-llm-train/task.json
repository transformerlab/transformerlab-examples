{
  "title": "Unsloth LLM Training Task",
  "name": "unsloth-llm-train-task",
  "command": "cd ~/unsloth-llm-train && python train.py",
  "cpus": "2",
  "memory": "4",
  "accelerators": "RTX3090:1",
  "setup": "uv pip install unsloth==2025.12.5 transformers datasets huggingface-hub torch transformerlab wandb",
  "env_vars": {
    "WANDB_PROJECT": "unsloth-llm-training",
    "PYTHONUNBUFFERED": "1",
    "HF_TOKEN": "ENTER YOUR HF_TOKEN HERE"
  },
  "description": "LLM training task using Unsloth FastLanguageModel with LoRA fine-tuning. Requires a Hugging Face token in HF_TOKEN env var for model access."
}