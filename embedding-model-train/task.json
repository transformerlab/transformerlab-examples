{
  "title": "Embedding Model Training Task",
  "name": "embedding-model-train-task",
  "command": "cd ~/embedding-model-train && python train.py",
  "accelerators": "RTX3090:1",
  "setup": "uv pip install transformerlab numpy==1.26.4 pyarrow==15.0.0 fsspec==2023.9.0 huggingface-hub==0.21.2 transformers==4.36.2 datasets==2.16.0 sentence-transformers==3.0.1 torch>=2.0.0 accelerate>=0.20.0",
  "env_vars": {
    "WANDB_PROJECT": "embedding-model-training",
    "PYTHONUNBUFFERED": "1",
    "HF_TOKEN": "ENTER YOUR HF_TOKEN HERE"
  },

  "parameters": {
    "model_name": "sentence-transformers/paraphrase-MiniLM-L3-v2",
    "dataset": "sentence-transformers/stsb",
    "dataset_type": "anchor | positive",
    "loss_function": "MultipleNegativesRankingLoss",
    "num_train_epochs": "1",
    "max_steps": "5",
    "max_samples": "100",
    "batch_size": "8",
    "learning_rate": "2e-5"
  },
  "description": "A task for training or fine-tuning embedding models using Sentence Transformers v3. Supports various dataset types and loss functions for training high-quality embeddings."
}
