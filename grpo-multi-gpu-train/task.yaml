name: grpo-multi-gpu-train-task
github_repo_url: https://github.com/transformerlab/transformerlab-examples
github_repo_dir: grpo-multi-gpu-train
resources:
  accelerators: "A100-80GB:1"
setup: "uv pip install trl bitsandbytes accelerate transformerlab datasets jinja2 wandb"
run: "cd ~/grpo-multi-gpu-train && python train.py"
envs:
  WANDB_PROJECT: "grpo-multi-gpu-training"
  WANDB_API_KEY: "{{secret._WANDB_API_KEY}}"
  PYTHONUNBUFFERED: "1"
  HF_TOKEN: "{{secret._HF_TOKEN}}"