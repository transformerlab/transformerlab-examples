name: mlx-lora-train-task
github_repo_url: https://github.com/transformerlab/transformerlab-examples
github_repo_dir: mlx_lora_train
setup: "source ~/venv/bin/activate; uv pip install transformerlab mlx mlx-lm datasets jinja2 transformers huggingface-hub pyyaml wandb"
run: "source ~/venv/bin/activate; cd ~/mlx_lora_train && python train.py"
envs:
  PYTHONUNBUFFERED: "1"
  HF_TOKEN: "{{secret._HF_TOKEN}}"
  WANDB_API_KEY: "{{secret._WANDB_API_KEY}}"
parameters:
  model_name: "mlx-community/Llama-3.2-1B-Instruct-4bit"
  dataset: "Trelis/touch-rugby-rules"
  adaptor_name: "adaptor"
  lora_layers: 16
  lora_rank: 8
  lora_alpha: 16
  learning_rate: 0.00005
  batch_size: 4
  iters: 1000
  num_train_epochs: -1
  steps_per_report: 100
  steps_per_eval: 200
  save_every: 100
  fuse_model: true
  log_to_wandb: false
  formatting_template: "{{prompt}} {{completion}}"
  prompt_column: "prompt"
  completion_column: "completion"
