name: autotrain-sft-train-task
github_repo_url: https://github.com/transformerlab/transformerlab-examples
github_repo_dir: autotrain-sft
resources:
  accelerators: "RTX3090:1"
setup: "uv pip install autotrain-advanced bitsandbytes transformerlab wandb"
run: "cd ~/autotrain-sft && python train.py"
envs:
  WANDB_PROJECT: "autotrain-sft-training"
  PYTHONUNBUFFERED: "1"
  HF_TOKEN: "{{secret._HF_TOKEN}}"
  WANDB_API_KEY: "{{secret._WANDB_API_KEY}}"
parameters:
  model_name: "microsoft/DialoGPT-small"
  dataset: "HuggingFaceH4/no_robots"
  learning_rate: 0.0002
  batch_size: 4
  num_train_epochs: 1
  max_steps: 10
  adaptor_name: "adaptor"
  formatting_template: "{% for message in messages %}{{ message.role | title }}: {{ message.content }}\n{% endfor %}"