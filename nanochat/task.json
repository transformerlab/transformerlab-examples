{
  "title": "Nanochat Speedrun Training",
  "name": "nanochat-train-task",
  "command": "cd ~/nanochat && python train.py",
  "accelerators": "H100:8",
  "setup": "uv pip install transformerlab torch torchvision torchaudio transformers datasets wandb maturin;sudo apt update;sudo apt install -y curl git build-essential rustc;",
  "env_vars": {
    "WANDB_PROJECT": "nanochat-training",
    "PYTHONUNBUFFERED": "1",
    "HF_TOKEN": "<your_huggingface_token_here>",
    "WANDB_API_KEY": "<your_wandb_api_key_here>"
  },
  "parameters": {
    "depth": "20",
    "nproc_per_node": "8",
    "enable_rl": "false",
    "log_to_wandb": "true"
  },
  "description": "A complete nanochat training task that runs the full speedrun pipeline including tokenizer training, base model pretraining, midtraining, supervised finetuning, and optional reinforcement learning on GSM8K. Requires 8xH100 GPUs and approximately 4 hours to complete."
}
