{
  "title": "LoRA Multi-GPU Training Task",
  "name": "lora-trainer-multi-gpu-task",
  "command": "cd ~/lora-trainer-multi-gpu && python train.py",
  "accelerators": "RTX3090:2",
  "setup": "uv pip install transformers trl peft bitsandbytes accelerate transformerlab datasets",
  "env_vars": {
    "WANDB_PROJECT": "lora-multi-gpu-training",
    "PYTHONUNBUFFERED": "1",
    "HF_TOKEN": "ENTER YOUR HF_TOKEN HERE"
  },
  "description": "A multi-GPU LoRA fine-tuning trainer for LLMs supporting Llama2, Qwen, Gemma, and other causal LMs with 4-bit quantization and accelerate multi-GPU support."
}
